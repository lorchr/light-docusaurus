<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Light Docusaurus Blog</title>
        <link>https://lorchr.github.io/light-docusaurus/blog</link>
        <description>Light Docusaurus Blog</description>
        <lastBuildDate>Fri, 22 Dec 2023 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>zh-Hans</language>
        <item>
            <title><![CDATA[Spring Boot Slice Upload with Minio(S3) and LocalFileSystem]]></title>
            <link>https://lorchr.github.io/light-docusaurus/blog/2023/12/22/file-slice-upload</link>
            <guid>https://lorchr.github.io/light-docusaurus/blog/2023/12/22/file-slice-upload</guid>
            <pubDate>Fri, 22 Dec 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[前言]]></description>
            <content:encoded><![CDATA[<h2 id="前言">前言</h2>
<h3 id="什么是-oss">什么是 OSS?</h3>
<p>OSS（Object Storage Service），对象存储服务，对象存储服务是一种使用 HTTP API 存储和检索对象的工具。就是将系统所要用的文件上传到云硬盘上，该云硬盘提供了文件下载、上传、预览等一系列服务，具备版本，权限控制能力，具备数据生命周期管理能力这样的服务以及技术可以统称为 OSS</p>
<p>一般项目使用 OSS 对象存储服务，主要是对图片、文件、音频等对象集中式管理权限控制，管理数据生命周期等等，提供上传，下载，预览，删除等功能。</p>
<h3 id="什么是-amazons3">什么是 AmazonS3？</h3>
<p>Amazon Simple Storage Service（Amazon S3，Amazon 简便存储服务）是 AWS 最早推出的云服务之一，经过多年的发展，S3 协议在对象存储行业事实上已经成为标准。</p>
<ul>
<li>提供了统一的接口 REST/SOAP 来统一访问任何数据</li>
<li>对 S3 来说，存在里面的数据就是对象名（键），和数据（值）</li>
<li>不限量，单个文件最高可达 5TB，可动态扩容。</li>
<li>高速。每个 bucket 下每秒可达 3500 PUT/COPY/POST/DELETE 或 5500 GET/HEAD 请求。</li>
<li>具备版本，权限控制能力</li>
<li>具备数据生命周期管理能力</li>
</ul>
<p>文档地址：<a href="https://docs.aws.amazon.com/zh_cn/AmazonS3/latest/userguide/Welcome.html">https://docs.aws.amazon.com/zh_cn/AmazonS3/latest/userguide/Welcome.html</a></p>
<p>作为一个对象存储服务，S3 功能真的很完备，行业的标杆，目前市面上大部分 OSS 对象存储服务都支持 AmazonS3，本文主要讲解的就是基于 AmazonS3 实现我们自己的 Spring Boot Starter。</p>
<ul>
<li>阿里云 OSS 兼容 S3</li>
<li>七牛云对象存储兼容 S3</li>
<li>腾讯云 COS 兼容 S3</li>
<li>Minio 兼容 S3</li>
</ul>
<h3 id="为什么要基于amazons3-实现-spring-boot-starter">为什么要基于AmazonS3 实现 Spring Boot Starter？</h3>
<p>原因：市面上 OSS 对象存储服务基本都支持 AmazonS3，我们封装我们的自己的 starter 那么就必须考虑适配，迁移，可扩展。比喻说我们今天使用的是阿里云 OSS 对接阿里云 OSS 的 SDK，后天我们使用的是腾讯 COS 对接是腾讯云 COS，我们何不直接对接 AmazonS3 实现呢，这样后续不需要调整代码，只需要去各个云服务商配置就好了。</p>
<h2 id="一自定义-spring-boot-starter-oss">一、自定义 spring-boot-starter-oss</h2>
<h3 id="11-maven工程定义及依赖-pomxml">1.1 Maven工程定义及依赖 pom.xml</h3>
<p>核心是引入 <code>AmazonS3</code> 依赖包</p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;com.amazonaws&lt;/groupId&gt;
    &lt;artifactId&gt;aws-java-sdk-s3&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p>完整的<code>pom.xml</code>如下</p>
<pre><code class="language-xml">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;artifactId&gt;cloud-sdk-oss&lt;/artifactId&gt;
    &lt;packaging&gt;jar&lt;/packaging&gt;

    &lt;name&gt;Cloud SDK OSS&lt;/name&gt;
    &lt;description&gt;OSS SDK Support Amazon S3, Alibaba OSS, Tencent COS, Qiniu, MinIO etc&lt;/description&gt;

    &lt;parent&gt;
        &lt;groupId&gt;com.light&lt;/groupId&gt;
        &lt;artifactId&gt;spring-cloud-samples&lt;/artifactId&gt;
        &lt;version&gt;2023.0.0&lt;/version&gt;
    &lt;/parent&gt;

    &lt;properties&gt;
        &lt;skipTests&gt;true&lt;/skipTests&gt;
    &lt;/properties&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.light&lt;/groupId&gt;
            &lt;artifactId&gt;cloud-common-core&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;com.amazonaws&lt;/groupId&gt;
            &lt;artifactId&gt;aws-java-sdk-s3&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;!--自动配置--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-autoconfigure-processor&lt;/artifactId&gt;
            &lt;optional&gt;true&lt;/optional&gt;
        &lt;/dependency&gt;
        &lt;!--生成配置说明文件--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;
            &lt;scope&gt;compile&lt;/scope&gt;
            &lt;optional&gt;true&lt;/optional&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;resources&gt;
            &lt;resource&gt;
                &lt;directory&gt;src/main/resources&lt;/directory&gt;
                &lt;!--yml中引用pom信息--&gt;
                &lt;filtering&gt;true&lt;/filtering&gt;
            &lt;/resource&gt;
        &lt;/resources&gt;

        &lt;plugins&gt;
            &lt;!--跳过向maven私服推送服务jar包--&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;skip&gt;true&lt;/skip&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
            &lt;!-- maven 打包时跳过测试 --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;skip&gt;true&lt;/skip&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
            &lt;!--可依赖jar包插件--&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;encoding&gt;${project.build.sourceEncoding}&lt;/encoding&gt;
                    &lt;source&gt;${maven.compiler.source}&lt;/source&gt;
                    &lt;target&gt;${maven.compiler.target}&lt;/target&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
            &lt;!-- 在打好的jar包中保留javadoc注释,实际会另外生成一个xxxxx-sources.jar --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;id&gt;attach-sources&lt;/id&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;jar&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;

&lt;/project&gt;
</code></pre>
<h3 id="12-oss操作类接口定义">1.2 OSS操作类接口定义</h3>
<p>OssTemplate：OSS 模板接口，此接口主要是对 OSS 操作的方法的一个接口，定义为接口主要是满足可扩展原则，就是其他人使用了我们的 jar 包，实现此接口可以自定义相关操作。</p>
<p>如下面所示代码：定义了一些对 OSS 操作的方法。</p>
<pre><code class="language-java">package com.light.cloud.sdk.oss.service;

import java.io.InputStream;
import java.util.Date;
import java.util.List;
import java.util.Map;

import com.amazonaws.services.s3.model.Bucket;
import com.amazonaws.services.s3.model.CompleteMultipartUploadResult;
import com.amazonaws.services.s3.model.CopyObjectResult;
import com.amazonaws.services.s3.model.InitiateMultipartUploadResult;
import com.amazonaws.services.s3.model.MultipartUpload;
import com.amazonaws.services.s3.model.ObjectMetadata;
import com.amazonaws.services.s3.model.PartSummary;
import com.amazonaws.services.s3.model.PutObjectResult;
import com.amazonaws.services.s3.model.S3Object;
import com.amazonaws.services.s3.model.S3ObjectSummary;
import com.amazonaws.services.s3.model.UploadPartResult;

/**
 * OSS操作模板
 *
 * @author Hui Liu
 * @date 2023/5/9
 */
public interface OssTemplate {

    /**
     * 创建Bucket &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/AmazonS3/latest/API/API_CreateBucket.html &lt;p&gt;
     *
     * @param bucketName bucket名称
     * @return 存储桶
     */
    Bucket createBucket(String bucketName) throws Exception;

    /**
     * 获取所有的buckets &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListBuckets.html &lt;p&gt;
     *
     * @return 存储桶列表
     */
    List&lt;Bucket&gt; listBuckets() throws Exception;

    /**
     * 通过Bucket名称删除Bucket &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/AmazonS3/latest/API/API_DeleteBucket.html &lt;p&gt;
     *
     * @param bucketName bucket名称
     */
    void removeBucket(String bucketName) throws Exception;

    /**
     * 上传对象 &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutObject.html &lt;p&gt;
     *
     * @param bucketName  bucket名称
     * @param objectName  文件名称
     * @param inputStream 文件输入流
     * @param contextType 文件类型
     * @return 上传结果
     */
    PutObjectResult putObject(String bucketName, String objectName, InputStream inputStream, String contextType) throws Exception;


    /**
     * 上传对象 &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutObject.html &lt;p&gt;
     *
     * @param bucketName bucket名称
     * @param objectName 文件名称
     * @param stream     文件流
     * @return 上传结果
     */
    PutObjectResult putObject(String bucketName, String objectName, InputStream stream) throws Exception;

    /**
     * 获取对象元信息 &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObjectMetadata.html &lt;p&gt;
     *
     * @param bucketName bucket名称
     * @param objectName 文件名称
     * @return 文件对象
     */
    ObjectMetadata getObjectMetadata(String bucketName, String objectName);

    /**
     * 获取对象 &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html &lt;p&gt;
     *
     * @param bucketName bucket名称
     * @param objectName 文件名称
     * @return 文件对象
     */
    S3Object getObject(String bucketName, String objectName) throws Exception;

    /**
     * 复制对象 &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/AmazonS3/latest/API/API_CopyObject.html &lt;p&gt;
     *
     * @param bucketName    bucket名称
     * @param objectName    文件名称
     * @param newBucketName 新bucket名称
     * @param newObjectName 新文件名称
     */
    CopyObjectResult copyObject(String bucketName, String objectName, String newBucketName, String newObjectName) throws Exception;

    /**
     * 移动对象 &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/AmazonS3/latest/API/API_CopyObject.html &lt;p&gt;
     *
     * @param bucketName    bucket名称
     * @param objectName    文件名称
     * @param newBucketName 新bucket名称
     * @param newObjectName 新文件名称
     */
    void moveObject(String bucketName, String objectName, String newBucketName, String newObjectName) throws Exception;

    /**
     * 获取对象，分段获取 &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html &lt;p&gt;
     *
     * @param bucketName bucket名称
     * @param objectName 文件名称
     * @param startByte  开始字节
     * @param endByte    结束字节
     * @return 文件对象
     */
    S3Object getObjectWithRange(String bucketName, String objectName, Long startByte, Long endByte) throws Exception;

    /**
     * 获取对象的url &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/AmazonS3/latest/API/API_GeneratePresignedUrl.html &lt;p&gt;
     *
     * @param bucketName bucket名称
     * @param objectName 文件名称
     * @param expireAt   过期时间
     * @return 对象的URL
     */
    String getPreSignViewUrl(String bucketName, String objectName, Date expireAt) throws Exception;

    /**
     * 根据前缀查询对象 &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListObjects.html &lt;p&gt;
     *
     * @param bucketName bucket名称
     * @param recursive  是否递归查询
     * @return S3ObjectSummary 列表
     */
    List&lt;S3ObjectSummary&gt; listObjects(String bucketName, boolean recursive) throws Exception;

    /**
     * 根据前缀查询对象 &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListObjects.html &lt;p&gt;
     * AmazonS3：http://docs.aws.amazon.com/AmazonS3/latest/API/RESTBucketGET.html &lt;p&gt;
     *
     * @param bucketName bucket名称
     * @param prefix     前缀
     * @param recursive  是否递归查询
     * @return S3ObjectSummary 列表
     */
    List&lt;S3ObjectSummary&gt; listObjectsByPrefix(String bucketName, String prefix, boolean recursive) throws Exception;

    /**
     * 删除对象 &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/AmazonS3/latest/API/API_DeleteObject.html &lt;p&gt;
     *
     * @param bucketName bucket名称
     * @param objectName 文件名称
     */
    void removeObject(String bucketName, String objectName) throws Exception;

    /**
     * 判断文件是否存在 &lt;p&gt;
     * AmazonS3：
     *
     * @param bucketName bucket名称
     * @param objectName 文件名称
     * @throws Exception
     */
    Boolean doesObjectExist(String bucketName, String objectName) throws Exception;

    /**
     * 列出已经存在的分片 &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListParts.html &lt;p&gt;
     *
     * @param bucketName bucket名称
     * @param objectName 文件名称
     * @param uploadId   上传id
     * @throws Exception
     */
    List&lt;PartSummary&gt; listParts(String bucketName, String objectName, String uploadId) throws Exception;

    /**
     * 列出正在进行的上传操作 &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/zh_cn/AmazonS3/latest/API/API_ListMultipartUploads.html &lt;p&gt;
     *
     * @param bucketName bucket名称
     * @throws Exception
     */
    List&lt;MultipartUpload&gt; listMultiUploads(String bucketName) throws Exception;

    /**
     * 初始化分片上传任务 &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/AmazonS3/latest/API/API_CreateMultipartUpload.html &lt;p&gt;
     *
     * @param bucketName bucket名称
     * @param objectName 文件名称
     * @throws Exception
     */
    InitiateMultipartUploadResult initMultiUpload(String bucketName, String objectName) throws Exception;

    /**
     * 取消分片上传任务 &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/AmazonS3/latest/API/API_AbortMultipartUpload.html &lt;p&gt;
     *
     * @param bucketName bucket名称
     * @param objectName 文件名称
     * @param uploadId   上传id
     * @throws Exception
     */
    void abortMultiUpload(String bucketName, String objectName, String uploadId) throws Exception;

    /**
     * 上传分片 &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/AmazonS3/latest/API/API_UploadPart.html &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/AmazonS3/latest/API/API_UploadPartCopy.html &lt;p&gt;
     *
     * @param bucketName  bucket名称
     * @param objectName  文件名称
     * @param uploadId    上传id
     * @param inputStream 文件输入流
     * @param partNumber  分片号
     * @throws Exception
     */
    UploadPartResult uploadPart(String bucketName, String objectName, String uploadId,
                                InputStream inputStream, Integer partNumber) throws Exception;

    /**
     * 获取预签名上传url &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/AmazonS3/latest/API/API_GeneratePresignedUrl.html &lt;p&gt;
     *
     * @param bucketName bucket名称
     * @param objectName 文件名称
     * @param expireAt   过期时间
     * @param params     签名参数
     * @return 预签名上传URL
     * @throws Exception
     */
    String getPreSignUploadUrl(String bucketName, String objectName, Date expireAt, Map&lt;String, String&gt; params) throws Exception;

    /**
     * 合并分片 &lt;p&gt;
     * AmazonS3：https://docs.aws.amazon.com/AmazonS3/latest/API/API_CompleteMultipartUpload.html &lt;p&gt;
     * &lt;p&gt;
     * Note: Minio对象存储要求的最小分片是5MB {@link com.amazonaws.services.s3.AmazonS3#completeMultipartUpload(com.amazonaws.services.s3.model.CompleteMultipartUploadRequest)}
     *
     * @param bucketName bucket名称 bucket名称
     * @param objectName 文件名称 文件名
     * @param uploadId   上传id
     * @param chunkNum   分片数量
     * @return 上传结果
     * @throws Exception
     */
    CompleteMultipartUploadResult completeMultiUpload(String bucketName, String objectName, String uploadId, Integer chunkNum) throws Exception;
}
</code></pre>
<p>基于上面定义的 <code>OssTemplate</code> 接口，扩展了 <code>S3OssTemplate</code> <code>LfsOssTemplate</code>，分别对应与S3存储和本地文件存储</p>
<h3 id="13-oss操作类s3实现">1.3 OSS操作类S3实现</h3>
<p>实现 OssTemplate 里面的方法，调用 AmazonS3 JavaSDK 的方法实现。</p>
<p>AmazonS3 提供了众多的方法，这里就不写全部的了，公司要用到那些就写那些吧，后续扩展就行。</p>
<p>AmazonS3 接口地址: <a href="https://docs.aws.amazon.com/AmazonS3/latest/API/API_CreateBucket.html">https://docs.aws.amazon.com/AmazonS3/latest/API/API_CreateBucket.html</a></p>
<pre><code class="language-java">package com.light.cloud.sdk.oss.service.impl;

import java.io.ByteArrayInputStream;
import java.io.InputStream;
import java.net.URL;
import java.util.Date;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.stream.Collectors;

import org.apache.commons.collections4.MapUtils;
import org.apache.commons.lang3.StringUtils;

import org.springframework.http.MediaType;
import org.springframework.http.MediaTypeFactory;

import com.amazonaws.HttpMethod;
import com.amazonaws.services.s3.AmazonS3;
import com.amazonaws.services.s3.internal.Mimetypes;
import com.amazonaws.services.s3.model.AbortMultipartUploadRequest;
import com.amazonaws.services.s3.model.Bucket;
import com.amazonaws.services.s3.model.CompleteMultipartUploadRequest;
import com.amazonaws.services.s3.model.CompleteMultipartUploadResult;
import com.amazonaws.services.s3.model.CopyObjectRequest;
import com.amazonaws.services.s3.model.CopyObjectResult;
import com.amazonaws.services.s3.model.GeneratePresignedUrlRequest;
import com.amazonaws.services.s3.model.GetObjectRequest;
import com.amazonaws.services.s3.model.InitiateMultipartUploadRequest;
import com.amazonaws.services.s3.model.InitiateMultipartUploadResult;
import com.amazonaws.services.s3.model.ListMultipartUploadsRequest;
import com.amazonaws.services.s3.model.ListObjectsRequest;
import com.amazonaws.services.s3.model.ListPartsRequest;
import com.amazonaws.services.s3.model.MetadataDirective;
import com.amazonaws.services.s3.model.MultipartUpload;
import com.amazonaws.services.s3.model.MultipartUploadListing;
import com.amazonaws.services.s3.model.ObjectListing;
import com.amazonaws.services.s3.model.ObjectMetadata;
import com.amazonaws.services.s3.model.PartETag;
import com.amazonaws.services.s3.model.PartListing;
import com.amazonaws.services.s3.model.PartSummary;
import com.amazonaws.services.s3.model.PutObjectResult;
import com.amazonaws.services.s3.model.S3Object;
import com.amazonaws.services.s3.model.S3ObjectSummary;
import com.amazonaws.services.s3.model.UploadPartRequest;
import com.amazonaws.services.s3.model.UploadPartResult;
import com.amazonaws.util.IOUtils;
import com.light.cloud.common.core.exception.BizException;
import com.light.cloud.sdk.oss.properties.OssProperties;
import com.light.cloud.sdk.oss.service.OssTemplate;

/**
 * OSS操作业务实现
 *
 * @author Hui Liu
 * @date 2023/5/9
 */
public class S3OssTemplate implements OssTemplate {

    private final AmazonS3 amazonS3;

    private final OssProperties ossProperties;

    public S3OssTemplate(AmazonS3 amazonS3, OssProperties ossProperties) {
        this.amazonS3 = amazonS3;
        this.ossProperties = ossProperties;
    }

    @Override
    public Bucket createBucket(String bucketName) throws Exception {
        if (!amazonS3.doesBucketExistV2(bucketName)) {
            return amazonS3.createBucket((bucketName));
        }
        return null;
    }

    @Override
    public List&lt;Bucket&gt; listBuckets() throws Exception {
        return amazonS3.listBuckets();
    }

    @Override
    public void removeBucket(String bucketName) throws Exception {
        amazonS3.deleteBucket(bucketName);
    }

    @Override
    public PutObjectResult putObject(String bucketName, String objectName, InputStream inputStream, String contextType) throws Exception {
        return putObject(bucketName, objectName, inputStream, inputStream.available(), contextType);
    }

    @Override
    public PutObjectResult putObject(String bucketName, String objectName, InputStream stream) throws Exception {
        return putObject(bucketName, objectName, stream, stream.available(), Mimetypes.MIMETYPE_OCTET_STREAM);
    }

    private PutObjectResult putObject(String bucketName, String objectName, InputStream stream, long size,
                                      String contextType) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        byte[] bytes = IOUtils.toByteArray(stream);
        ObjectMetadata objectMetadata = new ObjectMetadata();
        objectMetadata.setContentLength(size);
        objectMetadata.setContentType(contextType);
        ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(bytes);
        // 上传
        return amazonS3.putObject(bucketName, objectName, byteArrayInputStream, objectMetadata);
    }

    @Override
    public ObjectMetadata getObjectMetadata(String bucketName, String objectName) {
        return amazonS3.getObjectMetadata(bucketName, objectName);
    }

    @Override
    public S3Object getObject(String bucketName, String objectName) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        return amazonS3.getObject(bucketName, objectName);
    }

    @Override
    public CopyObjectResult copyObject(String bucketName, String objectName, String newBucketName, String newObjectName) throws Exception {
        CopyObjectRequest request = new CopyObjectRequest();
        request.setSourceBucketName(bucketName);
        request.setSourceKey(objectName);
        request.setDestinationBucketName(newBucketName);
        request.setDestinationKey(newObjectName);
        request.setMetadataDirective(MetadataDirective.COPY.name());
        return amazonS3.copyObject(request);
    }

    @Override
    public void moveObject(String bucketName, String objectName, String newBucketName, String newObjectName) throws Exception {
        CopyObjectRequest request = new CopyObjectRequest();
        request.setSourceBucketName(bucketName);
        request.setSourceKey(objectName);
        request.setDestinationBucketName(newBucketName);
        request.setDestinationKey(newObjectName);
        request.setMetadataDirective(MetadataDirective.COPY.name());
        CopyObjectResult copyObjectResult = amazonS3.copyObject(request);

        if (Objects.nonNull(copyObjectResult)) {
            amazonS3.deleteObject(bucketName, objectName);
        }
    }

    @Override
    public S3Object getObjectWithRange(String bucketName, String objectName, Long startByte, Long endByte) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        GetObjectRequest request = new GetObjectRequest(bucketName, objectName)
                .withRange(startByte, endByte);
        return amazonS3.getObject(request);
    }

    @Override
    public String getPreSignViewUrl(String bucketName, String objectName, Date expireAt) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        GeneratePresignedUrlRequest request = new GeneratePresignedUrlRequest(bucketName, objectName)
                .withExpiration(expireAt)
                .withMethod(HttpMethod.PUT);
        URL url = amazonS3.generatePresignedUrl(request);
        return url.toString();
    }

    @Override
    public List&lt;S3ObjectSummary&gt; listObjects(String bucketName, boolean recursive) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        ListObjectsRequest request = new ListObjectsRequest();
        request.setBucketName(bucketName);
        ObjectListing objectListing = amazonS3.listObjects(request);
        return objectListing.getObjectSummaries();
    }

    @Override
    public List&lt;S3ObjectSummary&gt; listObjectsByPrefix(String bucketName, String prefix, boolean recursive) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        ListObjectsRequest request = new ListObjectsRequest();
        request.setBucketName(bucketName);
        request.setPrefix(prefix);
        ObjectListing objectListing = amazonS3.listObjects(request);
        return objectListing.getObjectSummaries();
    }

    @Override
    public void removeObject(String bucketName, String objectName) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        amazonS3.deleteObject(bucketName, objectName);
    }

    @Override
    public Boolean doesObjectExist(String bucketName, String objectName) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        return amazonS3.doesObjectExist(bucketName, objectName);
    }

    @Override
    public List&lt;PartSummary&gt; listParts(String bucketName, String objectName, String uploadId) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        ListPartsRequest request = new ListPartsRequest(bucketName, objectName, uploadId);
        PartListing partListing = amazonS3.listParts(request);
        return partListing.getParts();
    }

    @Override
    public List&lt;MultipartUpload&gt; listMultiUploads(String bucketName) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        ListMultipartUploadsRequest request = new ListMultipartUploadsRequest(bucketName);
        MultipartUploadListing result = amazonS3.listMultipartUploads(request);
        return result.getMultipartUploads();
    }

    @Override
    public InitiateMultipartUploadResult initMultiUpload(String bucketName, String objectName) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        String contentType = MediaTypeFactory.getMediaType(objectName)
                .orElse(MediaType.APPLICATION_OCTET_STREAM).toString();
        ObjectMetadata objectMetadata = new ObjectMetadata();
        objectMetadata.setContentType(contentType);
        InitiateMultipartUploadRequest request = new InitiateMultipartUploadRequest(bucketName, objectName)
                .withObjectMetadata(objectMetadata);
        return amazonS3.initiateMultipartUpload(request);
    }

    @Override
    public void abortMultiUpload(String bucketName, String objectName, String uploadId) throws Exception {
        AbortMultipartUploadRequest request = new AbortMultipartUploadRequest(bucketName, objectName, uploadId);
        amazonS3.abortMultipartUpload(request);
    }

    @Override
    public UploadPartResult uploadPart(String bucketName, String objectName, String uploadId,
                                       InputStream inputStream, Integer partNumber) throws Exception {
        byte[] bytes = IOUtils.toByteArray(inputStream);
        UploadPartRequest request = new UploadPartRequest()
                .withBucketName(bucketName)
                .withKey(objectName)
                .withUploadId(uploadId)
                .withPartNumber(partNumber)
                .withInputStream(new ByteArrayInputStream(bytes))
                .withPartSize(bytes.length);
        return amazonS3.uploadPart(request);
    }

    @Override
    public String getPreSignUploadUrl(String bucketName, String objectName, Date expireAt, Map&lt;String, String&gt; params) throws Exception {
        GeneratePresignedUrlRequest request = new GeneratePresignedUrlRequest(bucketName, objectName)
                .withExpiration(expireAt)
                .withMethod(HttpMethod.PUT);
        if (MapUtils.isNotEmpty(params)) {
            params.forEach(request::addRequestParameter);
        }
        return amazonS3.generatePresignedUrl(request).toString();
    }

    @Override
    public CompleteMultipartUploadResult completeMultiUpload(String bucketName, String objectName, String uploadId, Integer chunkNum) throws Exception {
        List&lt;PartSummary&gt; parts = listParts(bucketName, objectName, uploadId);
        if (!chunkNum.equals(parts.size())) {
            // 已上传分块数量与记录中的数量不对应，不能合并分块
            throw BizException.throwException("分片缺失，请重新上传");
        }
        List&lt;PartETag&gt; partETagList = parts.stream()
                .map(partSummary -&gt; new PartETag(partSummary.getPartNumber(), partSummary.getETag()))
                .collect(Collectors.toList());
        CompleteMultipartUploadRequest request = new CompleteMultipartUploadRequest()
                .withBucketName(bucketName)
                .withKey(objectName)
                .withUploadId(uploadId)
                .withPartETags(partETagList);
        return amazonS3.completeMultipartUpload(request);
    }

}
</code></pre>
<h3 id="14-oss操作类localfilesystem实现">1.4 OSS操作类LocalFileSystem实现</h3>
<p>实现 OssTemplate 里面的方法，基于本地文件系统实现。 主要是用于本地的演示，以及加深对文件系统的理解，不适用于生产环境。</p>
<pre><code class="language-java">package com.light.cloud.sdk.oss.service.impl;

import java.io.BufferedInputStream;
import java.io.BufferedOutputStream;
import java.io.ByteArrayInputStream;
import java.io.File;
import java.io.FileInputStream;
import java.io.FilenameFilter;
import java.io.InputStream;
import java.net.URI;
import java.nio.file.Files;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.Comparator;
import java.util.Date;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.UUID;

import org.apache.commons.io.FileUtils;
import org.apache.commons.lang3.ArrayUtils;
import org.apache.commons.lang3.StringUtils;

import org.springframework.http.MediaType;
import org.springframework.http.MediaTypeFactory;

import com.amazonaws.services.s3.internal.Mimetypes;
import com.amazonaws.services.s3.model.Bucket;
import com.amazonaws.services.s3.model.CompleteMultipartUploadResult;
import com.amazonaws.services.s3.model.CopyObjectResult;
import com.amazonaws.services.s3.model.InitiateMultipartUploadResult;
import com.amazonaws.services.s3.model.MultipartUpload;
import com.amazonaws.services.s3.model.ObjectMetadata;
import com.amazonaws.services.s3.model.PartSummary;
import com.amazonaws.services.s3.model.PutObjectResult;
import com.amazonaws.services.s3.model.S3Object;
import com.amazonaws.services.s3.model.S3ObjectSummary;
import com.amazonaws.services.s3.model.UploadPartResult;
import com.light.cloud.common.core.constant.BaseConstant;
import com.light.cloud.common.core.crypto.AESTool;
import com.light.cloud.common.core.exception.BizException;
import com.light.cloud.common.core.tool.DateTool;
import com.light.cloud.common.core.tool.JsonTool;
import com.light.cloud.sdk.oss.properties.OssProperties;
import com.light.cloud.sdk.oss.service.OssTemplate;

/**
 * 本地文件存储实现 LocalFileSystemTemplate
 *
 * @author Hui Liu
 * @date 2023/5/9
 */
public class LfsOssTemplate implements OssTemplate {

    public static final String DEFAULT_PART_BUCKET = "partUpload";
    private final OssProperties ossProperties;

    public LfsOssTemplate(OssProperties ossProperties) {
        this.ossProperties = ossProperties;
        URI endpoint = ossProperties.getEndpoint();
        File rootFolder = new File(endpoint);
        if (!rootFolder.exists()) {
            rootFolder.mkdirs();
        }
    }

    public File getRootFolder() {
        URI endpoint = ossProperties.getEndpoint();
        return new File(endpoint);
    }

    public File getBucketFolder(String bucketName) {
        URI endpoint = ossProperties.getEndpoint();
        return new File(endpoint.getPath(), bucketName);
    }

    public File getFile(String bucketName, String objectName) {
        URI endpoint = ossProperties.getEndpoint();
        File bucketFolder = new File(endpoint.getPath(), bucketName);
        return new File(bucketFolder, objectName);
    }

    public File getPartBucketFolder(String bucketName) {
        URI endpoint = ossProperties.getEndpoint();
        File partBucketFolder = new File(endpoint.getPath(), DEFAULT_PART_BUCKET);
        return new File(partBucketFolder, bucketName);
    }

    public File getPartFolder(String bucketName, String objectName, String uploadId) {
        URI endpoint = ossProperties.getEndpoint();
        File partBucketFolder = new File(endpoint.getPath(), DEFAULT_PART_BUCKET);
        File bucketFolder = new File(partBucketFolder, bucketName);
        return new File(bucketFolder, objectName + BaseConstant.UNDERSCORE + uploadId);
    }

    public String getPartFilename(String filename, Integer partNumber) {
        return filename + BaseConstant.DOT + partNumber;
    }

    public Integer getPartNumber(String partFilename) {
        String partNum = partFilename.substring(partFilename.lastIndexOf(BaseConstant.DOT) + 1);
        return Integer.parseInt(partNum);
    }

    public String getETag(String bucketName, String objectName) {
        return AESTool.encryptBase64(objectName, bucketName);
    }

    public static File[] listFiles(File file, String prefix, Boolean recursion) {
        if (Objects.isNull(file)) {
            return new File[0];
        }
        if (file.isFile()) {
            return new File[]{file};
        }
        FilenameFilter filenameFilter = (dir, name) -&gt; {
            if (dir.isDirectory()) {
                return recursion;
            }
            if (StringUtils.isNotBlank(prefix)) {
                return name.startsWith(prefix);
            }
            return true;
        };
        return file.listFiles(filenameFilter);
    }

    @Override
    public Bucket createBucket(String bucketName) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        File bucketFolder = getBucketFolder(bucketName);
        if (!bucketFolder.exists()) {
            bucketFolder.mkdirs();
        }
        Bucket bucket = new Bucket();
        bucket.setName(bucketName);
        bucket.setCreationDate(DateTool.now());
        return bucket;
    }

    @Override
    public List&lt;Bucket&gt; listBuckets() throws Exception {
        File rootFolder = getRootFolder();
        int idx = rootFolder.getPath().length() + 1;
        File[] folders = rootFolder.listFiles();
        if (ArrayUtils.isEmpty(folders)) {
            return Collections.emptyList();
        }

        List&lt;Bucket&gt; buckets = new ArrayList&lt;&gt;();
        Date now = DateTool.now();
        for (File folder : folders) {
            String path = folder.getPath();
            Bucket bucket = new Bucket();
            bucket.setName(path.substring(idx));
            bucket.setCreationDate(now);

            buckets.add(bucket);
        }
        return buckets;
    }

    @Override
    public void removeBucket(String bucketName) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        File bucketFolder = getBucketFolder(bucketName);
        bucketFolder.delete();
    }

    @Override
    public PutObjectResult putObject(String bucketName, String objectName, InputStream inputStream, String contextType) throws Exception {
        return putObject(bucketName, objectName, inputStream, inputStream.available(), contextType);
    }

    @Override
    public PutObjectResult putObject(String bucketName, String objectName, InputStream stream) throws Exception {
        return putObject(bucketName, objectName, stream, stream.available(), Mimetypes.MIMETYPE_OCTET_STREAM);
    }

    private PutObjectResult putObject(String bucketName, String objectName, InputStream stream, long size,
                                      String contextType) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        ObjectMetadata objectMetadata = new ObjectMetadata();
        objectMetadata.setContentLength(size);
        objectMetadata.setContentType(contextType);
        // 上传
        File file = getFile(bucketName, objectName);
        FileUtils.copyInputStreamToFile(stream, file);

        PutObjectResult result = new PutObjectResult();
        result.setETag(getETag(bucketName, objectName));
        result.setMetadata(objectMetadata);
        return result;
    }

    @Override
    public ObjectMetadata getObjectMetadata(String bucketName, String objectName) {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }

        File file = getFile(bucketName, objectName);
        String contentType = MediaTypeFactory.getMediaType(objectName)
                .orElse(MediaType.APPLICATION_OCTET_STREAM).toString();

        ObjectMetadata result = new ObjectMetadata();
        result.setLastModified(new Date(file.lastModified()));
        result.setContentLength(file.length());
        result.setContentType(contentType);
        return result;
    }

    @Override
    public S3Object getObject(String bucketName, String objectName) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }

        File file = getFile(bucketName, objectName);
        // 下载文件
        S3Object result = new S3Object();
        result.setBucketName(bucketName);
        result.setKey(objectName);
        result.setObjectContent(new FileInputStream(file));
        return result;
    }

    @Override
    public CopyObjectResult copyObject(String bucketName, String objectName, String newBucketName, String newObjectName) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }

        File file = getFile(bucketName, objectName);
        // 复制文件
        File newBucketFolder = getBucketFolder(newBucketName);
        if (!newBucketFolder.exists()) {
            newBucketFolder.mkdirs();
        }
        File newFile = getFile(newBucketName, newObjectName);
        FileUtils.copyFile(file, newFile);

        CopyObjectResult result = new CopyObjectResult();
        result.setETag(getETag(newBucketName, newObjectName));
        result.setLastModifiedDate(DateTool.now());
        return result;
    }

    @Override
    public void moveObject(String bucketName, String objectName, String newBucketName, String newObjectName) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }

        File file = getFile(bucketName, objectName);
        // 复制文件
        File newBucketFolder = getBucketFolder(newBucketName);
        if (!newBucketFolder.exists()) {
            newBucketFolder.mkdirs();
        }
        File newFile = getFile(newBucketName, newObjectName);
        FileUtils.copyFile(file, newFile);
        // 删除文件
        file.delete();
    }

    @Override
    public S3Object getObjectWithRange(String bucketName, String objectName, Long startByte, Long endByte) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        File file = getFile(bucketName, objectName);
        FileInputStream inputStream = new FileInputStream(file);

        // 获取指定范围的字节
        byte[] buffer = new byte[(int) (endByte - startByte + 1)];
        inputStream.skip(startByte);
        int byteRead = inputStream.read(buffer);
        if (byteRead &lt;= 0) {
            return null;
        }
        // 下载文件
        S3Object result = new S3Object();
        result.setBucketName(bucketName);
        result.setKey(objectName);
        result.setObjectContent(new ByteArrayInputStream(buffer, 0, byteRead));
        return result;
    }

    @Override
    public String getPreSignViewUrl(String bucketName, String objectName, Date expireAt) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        Map&lt;String, Object&gt; urlParam = new HashMap&lt;&gt;();
        urlParam.put("bucketName", bucketName);
        urlParam.put("objectName", objectName);
        urlParam.put("expireAt", DateTool.format(expireAt, DateTool.PATTERN_YYYYMMDDHHMMSS));
        URI uri = URI.create(ossProperties.getPreSignUrl() + BaseConstant.SLASH + AESTool.encryptBase64(JsonTool.beanToJson(urlParam)));
        return uri.toString();
    }

    @Override
    public List&lt;S3ObjectSummary&gt; listObjects(String bucketName, boolean recursive) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        File bucketFolder = getBucketFolder(bucketName);
        if (!bucketFolder.exists()) {
            return Collections.emptyList();
        }

        File[] subFiles = listFiles(bucketFolder, null, recursive);

        List&lt;S3ObjectSummary&gt; summaryList = new ArrayList&lt;&gt;();
        for (File subFile : subFiles) {
            if (subFile.isDirectory()) {
                continue;
            }
            S3ObjectSummary s3ObjectSummary = new S3ObjectSummary();
            s3ObjectSummary.setBucketName(bucketName);
            s3ObjectSummary.setKey(subFile.getName());
            s3ObjectSummary.setLastModified(new Date(subFile.lastModified()));
            s3ObjectSummary.setSize(subFile.length());
            s3ObjectSummary.setETag(getETag(bucketName, subFile.getName()));

            summaryList.add(s3ObjectSummary);
        }
        return summaryList;
    }

    @Override
    public List&lt;S3ObjectSummary&gt; listObjectsByPrefix(String bucketName, String prefix, boolean recursive) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        File bucketFolder = getBucketFolder(bucketName);
        if (!bucketFolder.exists()) {
            return Collections.emptyList();
        }
        File[] subFiles = listFiles(bucketFolder, prefix, recursive);

        List&lt;S3ObjectSummary&gt; summaryList = new ArrayList&lt;&gt;();
        for (File subFile : subFiles) {
            if (subFile.isDirectory()) {
                continue;
            }
            S3ObjectSummary s3ObjectSummary = new S3ObjectSummary();
            s3ObjectSummary.setBucketName(bucketName);
            s3ObjectSummary.setKey(subFile.getName());
            s3ObjectSummary.setLastModified(new Date(subFile.lastModified()));
            s3ObjectSummary.setSize(subFile.length());
            s3ObjectSummary.setETag(getETag(bucketName, subFile.getName()));

            summaryList.add(s3ObjectSummary);
        }
        return summaryList;
    }

    @Override
    public void removeObject(String bucketName, String objectName) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        File file = getFile(bucketName, objectName);
        file.delete();
    }

    @Override
    public Boolean doesObjectExist(String bucketName, String objectName) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        File file = getFile(bucketName, objectName);
        return file.exists();
    }

    @Override
    public List&lt;PartSummary&gt; listParts(String bucketName, String objectName, String uploadId) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        File partFolder = getPartFolder(bucketName, objectName, uploadId);
        File[] partFiles = partFolder.listFiles();
        if (ArrayUtils.isEmpty(partFiles)) {
            return Collections.emptyList();
        }

        List&lt;PartSummary&gt; parts = new ArrayList&lt;&gt;();
        for (File partFile : partFiles) {
            String partFilename = partFile.getName();
            Integer partNumber = getPartNumber(partFilename);
            PartSummary partSummary = new PartSummary();
            partSummary.setPartNumber(partNumber);
            partSummary.setSize(partFile.length());
            partSummary.setETag(getETag(bucketName, partFilename));
            partSummary.setLastModified(new Date(partFile.lastModified()));

            parts.add(partSummary);
        }
        return parts;
    }

    @Override
    public List&lt;MultipartUpload&gt; listMultiUploads(String bucketName) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        File partBucketFolder = getPartBucketFolder(bucketName);
        File[] partFolders = partBucketFolder.listFiles();
        if (ArrayUtils.isEmpty(partFolders)) {
            return Collections.emptyList();
        }

        List&lt;MultipartUpload&gt; uploads = new ArrayList&lt;&gt;();
        for (File partFolder : partFolders) {
            String partFolderName = partFolder.getName();
            String[] split = partFolderName.split("_");
            MultipartUpload multipartUpload = new MultipartUpload();
            multipartUpload.setUploadId(split[1]);
            multipartUpload.setKey(split[0]);

            uploads.add(multipartUpload);
        }
        return uploads;
    }

    @Override
    public InitiateMultipartUploadResult initMultiUpload(String bucketName, String objectName) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        String uploadId = UUID.randomUUID().toString().replace(BaseConstant.DASH, BaseConstant.EMPTY);

        File partFolder = getPartFolder(bucketName, objectName, uploadId);
        if (!partFolder.exists()) {
            partFolder.mkdirs();
        }

        InitiateMultipartUploadResult result = new InitiateMultipartUploadResult();
        result.setBucketName(bucketName);
        result.setKey(objectName);
        result.setUploadId(uploadId);
        return result;
    }

    @Override
    public void abortMultiUpload(String bucketName, String objectName, String uploadId) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        File partFolder = getPartFolder(bucketName, objectName, uploadId);
        partFolder.delete();
    }

    @Override
    public UploadPartResult uploadPart(String bucketName, String objectName, String uploadId,
                                       InputStream inputStream, Integer partNumber) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        File partFolder = getPartFolder(bucketName, objectName, uploadId);
        // 上传分片
        File partFile = new File(partFolder, getPartFilename(objectName, partNumber));
        FileUtils.copyInputStreamToFile(inputStream, partFile);

        UploadPartResult result = new UploadPartResult();
        result.setETag(getETag(bucketName, partFile.getName()));
        result.setPartNumber(partNumber);
        return result;
    }

    @Override
    public String getPreSignUploadUrl(String bucketName, String objectName, Date expireAt, Map&lt;String, String&gt; params) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        Map&lt;String, Object&gt; urlParam = new HashMap&lt;&gt;(8);
        urlParam.put("bucketName", bucketName);
        urlParam.put("objectName", objectName);
        urlParam.put("expireAt", DateTool.format(expireAt, DateTool.PATTERN_YYYYMMDDHHMMSS));
        urlParam.putAll(params);
        URI uri = URI.create(ossProperties.getPreSignUrl() + BaseConstant.SLASH + AESTool.encryptBase64(JsonTool.beanToJson(urlParam)));
        return uri.toString();
    }

    @Override
    public CompleteMultipartUploadResult completeMultiUpload(String bucketName, String objectName, String uploadId, Integer chunkNum) throws Exception {
        if (StringUtils.isBlank(bucketName)) {
            bucketName = ossProperties.getDefaultBucket();
        }
        // 合并前的分片文件夹
        File partFolder = getPartFolder(bucketName, objectName, uploadId);
        File[] parts = partFolder.listFiles();
        if (ArrayUtils.isEmpty(parts) || !chunkNum.equals(parts.length)) {
            // 已上传分块数量与记录中的数量不对应，不能合并分块
            throw BizException.throwException("分片缺失，请重新上传");
        }

        // 合并后的文件
        File mergeFile = getFile(bucketName, objectName);
        // 执行合并
        try (BufferedOutputStream outputStream = new BufferedOutputStream(Files.newOutputStream(mergeFile.toPath()))) {
            List&lt;File&gt; partList = Arrays.stream(parts).sorted(Comparator.comparing(File::getName)).toList();

            int len;
            byte[] bytes = new byte[1024];
            for (File part : partList) {
                BufferedInputStream inputStream = new BufferedInputStream(Files.newInputStream(part.toPath()));

                while ((len = inputStream.read(bytes)) != -1) {
                    outputStream.write(bytes, 0, len);
                }
                inputStream.close();
            }
        }
        CompleteMultipartUploadResult result = new CompleteMultipartUploadResult();
        result.setBucketName(bucketName);
        result.setKey(objectName);
        result.setETag(getETag(bucketName, mergeFile.getName()));
        return result;
    }

}
</code></pre>
<h3 id="15-oss配置属性类-ossproperties">1.5 OSS配置属性类 OssProperties</h3>
<p>OssTemplate 相关的配置属性，方便客户端进行定制化配置，可以根据需求进行属性增删</p>
<pre><code class="language-java">package com.light.cloud.sdk.oss.properties;

import java.net.URI;

import org.springframework.boot.context.properties.ConfigurationProperties;

import lombok.Data;

/**
 * OSS属性配置
 *
 * @author Hui Liu
 * @date 2023/5/9
 */
@Data
@ConfigurationProperties(prefix = OssProperties.PREFIX)
public class OssProperties {

    public static final String PREFIX = "light.cloud.oss";

    /**
     * 对象存储服务的URL
     */
    private URI endpoint;

    /**
     * 区域
     */
    private String region;

    /**
     * true path-style nginx 反向代理和S3默认支持 pathStyle模式 {http://endpoint/bucketname}
     * false supports virtual-hosted-style 阿里云等需要配置为 virtual-hosted-style 模式{http://bucketname.endpoint}
     * 只是url的显示不一样
     */
    private Boolean pathStyleAccess = true;

    /**
     * Access key
     */
    private String accessKey;

    /**
     * Secret key
     */
    private String secretKey;

    /**
     * 默认的读写 Bucket
     */
    private String defaultBucket;

    /**
     * 预签名地址
     */
    private String preSignUrl;

    /**
     * 最大线程数，默认：100
     */
    private Integer maxConnections = 100;

    /**
     * 使用本地文件系统 use Local FileSystem
     */
    public Boolean local = false;

}
</code></pre>
<h3 id="16-oss自动配置类-ossautoconfiguration">1.6 OSS自动配置类 OssAutoConfiguration</h3>
<p>自动装配类，将 OssTemplate 实现注入到Spring 容器中，开箱即用。</p>
<pre><code class="language-java">package com.light.cloud.sdk.oss.configuration;

import org.springframework.boot.autoconfigure.condition.ConditionalOnBean;
import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;
import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
import org.springframework.boot.context.properties.EnableConfigurationProperties;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

import com.amazonaws.ClientConfiguration;
import com.amazonaws.auth.AWSCredentials;
import com.amazonaws.auth.AWSCredentialsProvider;
import com.amazonaws.auth.AWSStaticCredentialsProvider;
import com.amazonaws.auth.BasicAWSCredentials;
import com.amazonaws.client.builder.AwsClientBuilder;
import com.amazonaws.services.s3.AmazonS3;
import com.amazonaws.services.s3.AmazonS3Client;
import com.light.cloud.sdk.oss.properties.OssProperties;
import com.light.cloud.sdk.oss.service.OssTemplate;
import com.light.cloud.sdk.oss.service.impl.LfsOssTemplate;
import com.light.cloud.sdk.oss.service.impl.S3OssTemplate;
import lombok.RequiredArgsConstructor;

/**
 * OSS配置类
 *
 * @author Hui Liu
 * @date 2023/5/9
 */
@Configuration
@RequiredArgsConstructor
@EnableConfigurationProperties(OssProperties.class)
public class OssAutoConfiguration {

    @Bean
    @ConditionalOnMissingBean
    @ConditionalOnProperty(prefix = OssProperties.PREFIX, name = "local", havingValue = "false", matchIfMissing = true)
    public AmazonS3 ossClient(OssProperties ossProperties) {
        // 客户端配置，主要是全局的配置信息
        ClientConfiguration clientConfiguration = new ClientConfiguration();
        clientConfiguration.setMaxConnections(ossProperties.getMaxConnections());
        // url以及region配置
        AwsClientBuilder.EndpointConfiguration endpointConfiguration = new AwsClientBuilder.EndpointConfiguration(
                ossProperties.getEndpoint().toString(), ossProperties.getRegion());
        // 凭证配置
        AWSCredentials awsCredentials = new BasicAWSCredentials(ossProperties.getAccessKey(),
                ossProperties.getSecretKey());
        AWSCredentialsProvider awsCredentialsProvider = new AWSStaticCredentialsProvider(awsCredentials);
        // build amazonS3Client客户端
        return AmazonS3Client.builder().withEndpointConfiguration(endpointConfiguration)
                .withClientConfiguration(clientConfiguration).withCredentials(awsCredentialsProvider)
                .disableChunkedEncoding().withPathStyleAccessEnabled(ossProperties.getPathStyleAccess()).build();
    }

    @Bean
    @ConditionalOnBean(AmazonS3.class)
    public OssTemplate ossTemplate(AmazonS3 amazonS3, OssProperties ossProperties) {
        return new S3OssTemplate(amazonS3, ossProperties);
    }

    @Bean
    @ConditionalOnProperty(prefix = OssProperties.PREFIX, name = "local", havingValue = "true")
    public OssTemplate lfsOssTemplate(OssProperties ossProperties) {
        return new LfsOssTemplate(ossProperties);
    }

}
</code></pre>
<h3 id="17-springboot自动装配配置文件">1.7 SpringBoot自动装配配置文件</h3>
<h4 id="171-spring-boot-2x">1.7.1 Spring Boot 2.x</h4>
<p>Spring Boot 2.x的自动装配文件 <code>resouces/META-INF/spring.factories</code></p>
<pre><code class="language-factories"># Auto Configure
org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
  com.light.cloud.sdk.oss.configuration.OssAutoConfiguration
</code></pre>
<h4 id="172-spring-boot-3x">1.7.2 Spring Boot 3.x</h4>
<p>Spring Boot 2.x的自动装配文件 <code>resouces/META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports</code></p>
<pre><code class="language-imports">com.light.cloud.sdk.oss.configuration.OssAutoConfiguration
</code></pre>
<h3 id="18-applicationyaml配置示例">1.8 application.yaml配置示例</h3>
<pre><code class="language-yaml"># 使用MinIO S3 Aliyun Tencent登OSS存储
light:
  cloud:
    oss:
      endpoint: http://127.0.0.1:9000
      access-key: admin
      secret-key: secret
      default-bucket: light
      pre-sign-url: http://127.0.0.1:9001
      region: cn-wuhan
      max-connections: 100
      path-style-access: true
      local: false

---

# 使用本地文件系统 LocalFileSystem
light:
  cloud:
    oss:
      endpoint: file:///d:/storage/
      default-bucket: light
      pre-sign-url: http://127.0.0.1:80/file
      local: true

</code></pre>
<h2 id="二环境准备">二、环境准备</h2>
<h3 id="21-搭建minio-server">2.1 搭建MinIO Server</h3>
<pre><code class="language-shell">docker run -d \
  --publish 9000:9000 \
  --publish 9001:9001 \
  --volume //d/docker/minio/data:/data \
  --env MINIO_ROOT_USER=minioaccess \
  --env MINIO_ROOT_PASSWORD=miniosecret \
  --env MINIO_SERVER_URL=http://minio.example.net:9000 \
  --net dev \
  --restart=on-failure:3 \
  --name minio \
  minio/minio:RELEASE.2023-05-18T00-05-36Z server /data --console-address ":9001"
</code></pre>
<h3 id="22-初始化数据库">2.2 初始化数据库</h3>
<p>以下为pgsql数据库脚本示例</p>
<pre><code class="language-sql">-- ----------------------------
-- Table structure for slice_upload
-- ----------------------------
DROP TABLE IF EXISTS "public"."slice_upload";
CREATE TABLE "public"."slice_upload"
(
    "id"                int8                                        NOT NULL,
    "file_identifier"   varchar(64) COLLATE "pg_catalog"."default"  NOT NULL,
    "filename"          varchar(255) COLLATE "pg_catalog"."default" NOT NULL,
    "bucket_name"       varchar(64) COLLATE "pg_catalog"."default"  NOT NULL,
    "object_name"       varchar(255) COLLATE "pg_catalog"."default" NOT NULL,
    "upload_id"         varchar(255) COLLATE "pg_catalog"."default" NOT NULL,
    "total_size"        int8                                        NOT NULL,
    "chunk_size"        int8                                        NOT NULL,
    "chunk_num"         int4                                        NOT NULL,
    "deleted"           int4                                        NOT NULL,
    "data_dept_id"      int8                                        NOT NULL,
    "remark"            varchar(255) COLLATE "pg_catalog"."default",
    "created_user"      int8                                        NOT NULL,
    "created_user_name" varchar(32) COLLATE "pg_catalog"."default"  NOT NULL,
    "created_time"      timestamp(6)                                NOT NULL,
    "updated_user"      int8                                        NOT NULL,
    "updated_user_name" varchar(32) COLLATE "pg_catalog"."default"  NOT NULL,
    "updated_time"      timestamp(6)                                NOT NULL,
    "revision"          int4                                        NOT NULL,
    "tenant_id"         int8                                        NOT NULL
);

COMMENT ON COLUMN "public"."slice_upload"."id" IS '主键';
COMMENT ON COLUMN "public"."slice_upload"."file_identifier" IS '文件唯一标识 MD5';
COMMENT ON COLUMN "public"."slice_upload"."filename" IS '文件名';
COMMENT ON COLUMN "public"."slice_upload"."bucket_name" IS 'S3存储桶';
COMMENT ON COLUMN "public"."slice_upload"."object_name" IS 'S3文件的key';
COMMENT ON COLUMN "public"."slice_upload"."upload_id" IS 'S3分片上传的 uploadId';
COMMENT ON COLUMN "public"."slice_upload"."total_size" IS '文件大小 bytes';
COMMENT ON COLUMN "public"."slice_upload"."chunk_size" IS '每个分片大小 bytes';
COMMENT ON COLUMN "public"."slice_upload"."chunk_num" IS '分片数量';
COMMENT ON COLUMN "public"."slice_upload"."deleted" IS '是否删除;0-否；1-是';
COMMENT ON COLUMN "public"."slice_upload"."data_dept_id" IS '数据所属部门id';
COMMENT ON COLUMN "public"."slice_upload"."remark" IS '备注';
COMMENT ON COLUMN "public"."slice_upload"."created_user" IS '创建人Id';
COMMENT ON COLUMN "public"."slice_upload"."created_user_name" IS '创建人';
COMMENT ON COLUMN "public"."slice_upload"."created_time" IS '创建时间';
COMMENT ON COLUMN "public"."slice_upload"."updated_user" IS '更新人Id';
COMMENT ON COLUMN "public"."slice_upload"."updated_user_name" IS '更新人';
COMMENT ON COLUMN "public"."slice_upload"."updated_time" IS '更新时间';
COMMENT ON COLUMN "public"."slice_upload"."revision" IS '乐观锁';
COMMENT ON COLUMN "public"."slice_upload"."tenant_id" IS '租户号';
COMMENT ON TABLE "public"."slice_upload" IS '分片上传表';

-- ----------------------------
-- Primary Key structure for table slice_upload
-- ----------------------------
ALTER TABLE "public"."slice_upload"
    ADD CONSTRAINT "slice_upload_pkey" PRIMARY KEY ("id");

</code></pre>
<h2 id="三使用示例">三、使用示例</h2>
<p>对于文件的简单操作接口示例，包括</p>
<ul>
<li>添加存储桶</li>
<li>删除存储桶</li>
<li>获取存储桶列表</li>
<li>获取文件列表</li>
<li>上传文件</li>
<li>下载文件</li>
<li>获取文件的预览url</li>
</ul>
<h3 id="31-接口定义">3.1 接口定义</h3>
<pre><code class="language-java">@RestController
@RequestMapping("/oss")
@Tags(value = {
        @Tag(name = "【1.0.0】-【OSS】")
})
public class OssController {

    @Autowired(required = false)
    private FileService fileService;

    @PostMapping("bucket/create")
    @Operation(summary = "【新建存储桶】", description = "Hui Liu")
    @Parameters(value = {
            @Parameter(name = "bucketName", description = "bucket", in = ParameterIn.QUERY)
    })
    public Result&lt;Bucket&gt; createBucket(@RequestParam String bucketName) throws Exception {
        Bucket result = fileService.createBucket(bucketName);
        return Result.success(result);
    }

    @GetMapping("bucket/list")
    @Operation(summary = "【存储桶列表】", description = "Hui Liu")
    public Result&lt;List&lt;Bucket&gt;&gt; listBucket() throws Exception {
        List&lt;Bucket&gt; results = fileService.listBuckets();
        return Result.success(results);
    }

    @DeleteMapping("bucket/delete")
    @Operation(summary = "【删除存储桶】", description = "Hui Liu")
    @Parameters(value = {
            @Parameter(name = "bucketName", description = "bucket", in = ParameterIn.QUERY)
    })
    public Result&lt;Boolean&gt; removeBucket(@RequestParam String bucketName) throws Exception {
        fileService.removeBucket(bucketName);
        return Result.success(true);
    }

    @GetMapping("list")
    @Operation(summary = "【文件列表】", description = "Hui Liu")
    @Parameters(value = {
            @Parameter(name = "bucketName", description = "bucket", in = ParameterIn.QUERY)
    })
    public Result&lt;List&lt;S3ObjectSummary&gt;&gt; list(String bucketName) throws Exception {
        List&lt;S3ObjectSummary&gt; results = fileService.listObjects(bucketName, true);
        return Result.success(results);
    }

    @PostMapping("upload")
    @Operation(summary = "【上传文件】", description = "Hui Liu")
    @Parameters(value = {
            @Parameter(name = "file", description = "文件", in = ParameterIn.QUERY)
    })
    public Result&lt;PutObjectResult&gt; upload(MultipartFile file) throws Exception {
        PutObjectResult result = fileService.putObject(null, file.getOriginalFilename(), file.getInputStream(), file.getContentType());
        return Result.success(result);
    }

    @PostMapping("preview")
    @Operation(summary = "【获取预览url】", description = "Hui Liu")
    @Parameters(value = {
            @Parameter(name = "filename", description = "文件名", in = ParameterIn.QUERY)
    })
    public Result&lt;String&gt; preview(@RequestParam String filename) throws Exception {
        String result = fileService.getPreSignViewUrl(null, filename, DateTool.fromNow(Duration.ofHours(1L)));
        return Result.success(result);
    }

    @GetMapping("download")
    @Operation(summary = "【下载文件】", description = "Hui Liu")
    @Parameters(value = {
            @Parameter(name = "filename", description = "文件名", in = ParameterIn.QUERY)
    })
    public void download(@RequestParam String filename, HttpServletResponse response) throws Exception {
        S3Object object = fileService.getObject(null, filename);
        byte[] results = object.getObjectContent().readAllBytes();
        download(response, filename, results);
    }

    public void download(HttpServletResponse response, String filename, byte[] bytes) throws IOException {
        try {
            // 防止中文乱码
            String encodedFilename = URLEncoder.encode(filename, StandardCharsets.UTF_8.name())
                    .replaceAll("\\+", "%20");

            MediaType mediaType = MediaTypeFactory.getMediaType(filename)
                    .orElse(MediaType.APPLICATION_OCTET_STREAM);

            HttpHeaders headers = new HttpHeaders();
            headers.setContentLength(bytes.length);
            headers.setContentType(mediaType);
            headers.setAccessControlAllowOrigin("*");
            headers.setContentDisposition(ContentDisposition.attachment().filename(encodedFilename).build());

            for (Map.Entry&lt;String, List&lt;String&gt;&gt; entry : headers.entrySet()) {
                response.setHeader(entry.getKey(), entry.getValue().getFirst());
            }
            ServletOutputStream outputStream = response.getOutputStream();
            outputStream.write(bytes);
            outputStream.flush();
        } catch (Exception e) {
            throw BizException.throwException(ResponseEnum.EXCEL_EXPORT_ERROR.getDesc(), e);
        }
    }
}
</code></pre>
<h3 id="32-业务接口定义">3.2 业务接口定义</h3>
<pre><code class="language-java">public interface FileService {

    Bucket createBucket(String bucketName) throws Exception;

    List&lt;Bucket&gt; listBuckets() throws Exception;

    void removeBucket(String bucketName) throws Exception;

    List&lt;S3ObjectSummary&gt; listObjects(String bucketName, boolean recursive) throws Exception;

    PutObjectResult putObject(String bucketName, String objectName, InputStream inputStream, String contentType) throws Exception;

    String getPreSignViewUrl(String bucketName, String filename, Date expireAt) throws Exception;

    S3Object getObject(String bucketName, String filename) throws Exception;

}
</code></pre>
<h3 id="33-业务实现类">3.3 业务实现类</h3>
<pre><code class="language-java">@Slf4j
@Service
public class FileServiceImpl implements FileService {

    @Resource
    private OssTemplate ossTemplate;

    @Override
    public Bucket createBucket(String bucketName) throws Exception {
        return ossTemplate.createBucket(bucketName);
    }

    @Override
    public List&lt;Bucket&gt; listBuckets() throws Exception {
        return ossTemplate.listBuckets();
    }

    @Override
    public void removeBucket(String bucketName) throws Exception {
        ossTemplate.removeBucket(bucketName);
    }

    @Override
    public List&lt;S3ObjectSummary&gt; listObjects(String bucketName, boolean recursive) throws Exception {
        return ossTemplate.listObjects(bucketName, recursive);
    }

    @Override
    public PutObjectResult putObject(String bucketName, String objectName, InputStream inputStream, String contentType) throws Exception {
        return ossTemplate.putObject(bucketName, objectName, inputStream, contentType);
    }

    @Override
    public String getPreSignViewUrl(String bucketName, String filename, Date expireAt) throws Exception {
        return ossTemplate.getPreSignViewUrl(bucketName, filename, expireAt);
    }

    @Override
    public S3Object getObject(String bucketName, String filename) throws Exception {
        return ossTemplate.getObject(bucketName, filename);
    }

}
</code></pre>
<h3 id="34-接口调用示例">3.4 接口调用示例</h3>
<pre><code class="language-shell"># 创建bucket
curl -X POST 'http://localhost:10030/demo/oss/bucket/create?bucketName=test'

# 获取bucket列表
curl -X GET 'http://localhost:10030/demo/oss/bucket/list'

# 删除bucket
curl -X DELETE 'http://localhost:10030/demo/oss/bucket/delete?bucketName=test'

# 获取文件列表
curl -X GET 'http://localhost:10030/demo/oss/list?bucketName=test'

# 上传文件
curl -X POST 'http://localhost:10030/demo/oss/upload?bucketName=test'  -H "Content-Type: multipart/form-data" --form 'file=@C:/Users/light/Desktop/temp.yaml'

# 获取文件预览url
curl -X POST 'http://localhost:10030/demo/oss/preview?filename=temp'

# 下载文件
curl -X GET 'http://localhost:10030/demo/oss/download?filename=temp.yaml' -o temp.yaml
</code></pre>
<h2 id="四分片下载">四、分片下载</h2>
<p>支持将文件分片下载，可由客户端指定每个分片的大小</p>
<h3 id="41-接口定义">4.1 接口定义</h3>
<pre><code class="language-java">/**
 * 断点下载 &lt;p&gt;
 * https://mp.weixin.qq.com/s/HMIMpbDvuMmPU-ax43BzuA &lt;p&gt;
 * https://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html &lt;p&gt;
 * https://help.aliyun.com/document_detail/39571.html &lt;p&gt;
 */
@GetMapping("downloadChunk")
@Operation(summary = "【下载文件(支持分片)】", description = "Hui Liu")
@Parameters(value = {
        @Parameter(name = "bucketName", description = "bucket", in = ParameterIn.QUERY),
        @Parameter(name = "objectName", description = "文件名", in = ParameterIn.QUERY),
        @Parameter(name = "range", description = "下载的范围 bytes=0-, bytes=1024-2048, bytes=-4096", in = ParameterIn.QUERY),
})
public void downloadChunk(@RequestParam String bucketName, @RequestParam String objectName, @RequestParam(required = false) String range, HttpServletResponse response) throws Exception {
    ChunkDownload chunkDownload = fileService.downloadFile(bucketName, objectName, range);
    byte[] bytes = chunkDownload.getS3Object().getObjectContent().readAllBytes();
    download(response, bytes, chunkDownload.getStartByte(), chunkDownload.getEndByte());
}

public void download(HttpServletResponse response, byte[] bytes, Long startByte, Long endByte) throws IOException {
    // 设置HTTP响应头
    HttpHeaders headers = new HttpHeaders();
    headers.setContentLength(bytes.length);
    headers.set(HttpHeaders.CONTENT_RANGE, String.format("bytes %d-%d/%d", startByte, endByte, bytes.length));
    for (Map.Entry&lt;String, List&lt;String&gt;&gt; entry : headers.entrySet()) {
        response.setHeader(entry.getKey(), entry.getValue().getFirst());
    }
    // 设置响应状态码
    response.setStatus(HttpStatus.PARTIAL_CONTENT.value());
    // 设置响应字节
    ServletOutputStream outputStream = response.getOutputStream();
    outputStream.write(bytes);
    outputStream.flush();
}
</code></pre>
<h3 id="42-业务接口定义">4.2 业务接口定义</h3>
<pre><code class="language-java">/**
     * 下载文件 &lt;p&gt;
     * Tips： 支持断点下载
     *
     * @param bucketName 文件标识MD5
     * @param objectName 文件标识MD5
     * @param range      范围
     */
    ChunkDownload downloadFile(String bucketName, String objectName, String range) throws Exception;
</code></pre>
<h3 id="43-业务实现类">4.3 业务实现类</h3>
<pre><code class="language-java">@Override
public ChunkDownload downloadFile(String bucketName, String objectName, String range) throws Exception {
    ObjectMetadata objectMetadata = ossTemplate.getObjectMetadata(bucketName, objectName);
    Long totalSize = objectMetadata.getContentLength();
    // 处理字节信息
    ChunkDownload chunkDownload = executeRangeInfo(range, totalSize);

    // rangeInfo = null，直接下载整个文件
    S3Object s3Object = null;
    if (Objects.isNull(chunkDownload)) {
        chunkDownload = new ChunkDownload();
        s3Object = ossTemplate.getObject(bucketName, objectName);
    } else {
        // 下载部分文件
        s3Object = ossTemplate.getObjectWithRange(bucketName, objectName,
                chunkDownload.getStartByte(), chunkDownload.getEndByte());
    }

    chunkDownload.setTotalSize(totalSize);
    chunkDownload.setS3Object(s3Object);
    chunkDownload.setPartSize(s3Object.getObjectMetadata().getContentLength());
    return chunkDownload;
}

private ChunkDownload executeRangeInfo(String range, Long fileSize) {
    if (StringUtils.isEmpty(range) || !range.contains("bytes=") || !range.contains("-")) {
        return null;
    }

    long startByte = 0;
    long endByte = fileSize - 1;
    range = range.substring(range.lastIndexOf("=") + 1).trim();
    String[] ranges = range.split("-");
    if (ranges.length &lt;= 0 || ranges.length &gt; 2) {
        return null;
    }

    try {
        if (ranges.length == 1) {
            if (range.startsWith("-")) {
                // 1. 如：bytes=-1024  从开始字节到第1024个字节的数据
                endByte = Long.parseLong(ranges[0]);
            } else if (range.endsWith("-")) {
                // 2. 如：bytes=1024-  第1024个字节到最后字节的数据
                startByte = Long.parseLong(ranges[0]);
            }
        } else {
            // 3. 如：bytes=1024-2048  第1024个字节到2048个字节的数据
            startByte = Long.parseLong(ranges[0]);
            endByte = Long.parseLong(ranges[1]);
        }
    } catch (NumberFormatException e) {
        startByte = 0;
        endByte = fileSize - 1;
    }

    if (startByte &gt;= fileSize) {
        log.error("range error, startByte &gt;= fileSize. startByte: {}, fileSize: {}", startByte, fileSize);
        return null;
    }

    return BuilderTool.of(ChunkDownload.class)
            .with(ChunkDownload::setStartByte, startByte)
            .with(ChunkDownload::setEndByte, endByte)
            .build();
}
</code></pre>
<h3 id="44-接口调用示例">4.4 接口调用示例</h3>
<pre><code class="language-shell"># 下载分片1
curl -X GET 'http://localhost:10030/demo/oss/downloadChunk?bucketName=light&amp;objectName=temp.yaml&amp;range=bytes=0-102400' -o temp.yaml.1

# 下载分片2
curl -X GET 'http://localhost:10030/demo/oss/downloadChunk?bucketName=light&amp;objectName=temp.yaml&amp;range=bytes=102401-204800' -o temp.yaml.2

# 下载分片3
curl -X GET 'http://localhost:10030/demo/oss/downloadChunk?bucketName=light&amp;objectName=temp.yaml&amp;range=bytes=204801-' -o temp.yaml.3
</code></pre>
<h2 id="五分片上传">五、分片上传</h2>
<p>对于超大文件的上传，可以在前端对文件惊醒切分，分片上传</p>
<ul>
<li>校验当前文件是否存在</li>
<li>初始化上传任务</li>
<li>获取预签名的上传URL，前端直传到S3</li>
<li>上传分片</li>
<li>获取所有分片</li>
<li>合并分片</li>
</ul>
<h3 id="51-接口定义">5.1 接口定义</h3>
<pre><code class="language-java">@GetMapping("chunkUpload/validate/{identifier}")
@Operation(summary = "【断点续传：上传前的校验】", description = "Hui Liu")
@Parameters(value = {
        @Parameter(name = "identifier", description = "待上传文件的MD5", in = ParameterIn.PATH)
})
public Result&lt;TaskInfo&gt; validate(@PathVariable("identifier") String identifier) throws Exception {
    TaskInfo result = fileService.getTaskInfo(identifier);
    return Result.success(result);
}

@PostMapping("chunkUpload/initTask")
@Operation(summary = "【断点续传：初始化上传任务】", description = "Hui Liu")
public Result&lt;TaskInfo&gt; initTask(@RequestBody InitTaskParam param) throws Exception {
    TaskInfo result = fileService.initTask(param);
    return Result.success(result);
}

@GetMapping("chunkUpload/{identifier}/{partNumber}")
@Operation(summary = "【断点续传：获取分片的预签名上传地址】", description = "Hui Liu")
@Parameters(value = {
        @Parameter(name = "identifier", description = "待上传文件的MD5", in = ParameterIn.PATH),
        @Parameter(name = "partNumber", description = "分片号", in = ParameterIn.PATH)
})
public Result&lt;String&gt; preSignUploadUrl(@PathVariable("identifier") String identifier,
                                        @PathVariable("partNumber") Integer partNumber) throws Exception {
    TaskInfo taskInfo = fileService.getTaskInfo(identifier);
    if (Objects.isNull(taskInfo)) {
        Result.failure(400, "分片任务不存在");
    }
    Map&lt;String, String&gt; params = new HashMap&lt;&gt;(16);
    params.put("partNumber", partNumber.toString());
    params.put("uploadId", taskInfo.getUploadId());
    String result = fileService.getPreSignUploadUrl(taskInfo.getBucketName(), taskInfo.getObjectName(),
            DateTool.fromNow(Duration.ofHours(1L)), params);
    return Result.success(result);
}

@PostMapping("chunkUpload/uploadPart")
@Operation(summary = "【断点续传：上传分片】", description = "Hui Liu")
@Parameters(value = {
        @Parameter(name = "bucketName", description = "bucket", in = ParameterIn.QUERY),
        @Parameter(name = "objectName", description = "文件名", in = ParameterIn.QUERY),
        @Parameter(name = "uploadId", description = "上传id", in = ParameterIn.QUERY),
        @Parameter(name = "partNumber", description = "分片号", in = ParameterIn.QUERY),
})
public Result&lt;UploadPartResult&gt; uploadPart(@RequestParam String bucketName, @RequestParam String objectName,
                                            @RequestParam String uploadId, @RequestParam Integer partNumber,
                                            MultipartFile file) throws Exception {
    UploadPartResult result = fileService.uploadPart(bucketName, objectName, uploadId, file.getInputStream(), partNumber);
    return Result.success(result);
}

@GetMapping("chunkUpload/listParts")
@Operation(summary = "【断点续传：分片列表】", description = "Hui Liu")
@Parameters(value = {
        @Parameter(name = "bucketName", description = "bucket", in = ParameterIn.QUERY),
        @Parameter(name = "objectName", description = "文件名", in = ParameterIn.QUERY),
        @Parameter(name = "uploadId", description = "上传id", in = ParameterIn.QUERY),
})
public Result&lt;List&lt;PartSummary&gt;&gt; listParts(@RequestParam String bucketName, @RequestParam String objectName,
                                            @RequestParam String uploadId) throws Exception {
    List&lt;PartSummary&gt; results = fileService.listParts(bucketName, objectName, uploadId);
    return Result.success(results);
}

/**
 * 断点续传：合并分片
 */
@GetMapping("chunkUpload/merge/{identifier}")
@Operation(summary = "【断点续传：合并分片】", description = "Hui Liu")
@Parameters(value = {
        @Parameter(name = "identifier", description = "待上传文件的MD5", in = ParameterIn.PATH)
})
public Result&lt;CompleteMultipartUploadResult&gt; mergeParts(@PathVariable("identifier") String identifier) throws Exception {
    TaskInfo taskInfo = fileService.getTaskInfo(identifier);
    if (Objects.isNull(taskInfo)) {
        Result.failure(400, "分片任务不存在");
    }
    if (YesNoEnum.NO.eqValue(taskInfo.getFinish())) {
        CompleteMultipartUploadResult result = fileService.completeMultiUpload(taskInfo.getBucketName(), taskInfo.getObjectName(),
                taskInfo.getUploadId(), taskInfo.getChunkNum());

        return Result.success(result);
    }
    return Result.success(null);
}
</code></pre>
<h3 id="52-业务接口定义">5.2 业务接口定义</h3>
<pre><code class="language-java">/**
 * 根据文件的唯一标识获取文件信息
 */
TaskInfo getTaskInfo(String identifier) throws Exception;

/**
 * 初始化一个任务
 */
TaskInfo initTask(InitTaskParam param) throws Exception;

String getPreSignUploadUrl(String bucketName, String objectName, Date expireAt, Map&lt;String, String&gt; params) throws Exception;

UploadPartResult uploadPart(String bucketName, String objectName, String uploadId, InputStream inputStream, Integer partNumber) throws Exception;

List&lt;PartSummary&gt; listParts(String bucketName, String objectName, String uploadId) throws Exception;

CompleteMultipartUploadResult completeMultiUpload(String bucketName, String objectName, String uploadId, Integer chunkNum) throws Exception;
</code></pre>
<h3 id="53-业务实现类">5.3 业务实现类</h3>
<pre><code class="language-java">@Override
public TaskInfo getTaskInfo(String identifier) throws Exception {
    // 从DB查询分片信息
    SliceUpload sliceUpload = sliceUploadService.queryByIdentifier(identifier);

    // 没有分片信息，表示还未初始化分片上传任务
    if (Objects.isNull(sliceUpload)) {
        return null;
    }

    // 文件是否存在，存在表示上传完成，不存在表示未完成
    Boolean exists = ossTemplate.doesObjectExist(sliceUpload.getBucketName(), sliceUpload.getObjectName());
    if (exists) {
        return BuilderTool.of(TaskInfo.class)
                .with(TaskInfo::setFilename, sliceUpload.getFilename())
                .with(TaskInfo::setFileIdentifier, sliceUpload.getFileIdentifier())
                .with(TaskInfo::setBucketName, sliceUpload.getBucketName())
                .with(TaskInfo::setObjectName, sliceUpload.getObjectName())
                .with(TaskInfo::setUploadId, sliceUpload.getUploadId())
                .with(TaskInfo::setTotalSize, sliceUpload.getTotalSize())
                .with(TaskInfo::setChunkSize, sliceUpload.getChunkSize())
                .with(TaskInfo::setChunkNum, sliceUpload.getChunkNum())
                .with(TaskInfo::setFinish, YesNoEnum.YES.getValue())
                .build();
    }
    // 查询已完成的分片
    List&lt;PartSummary&gt; parts = ossTemplate.listParts(sliceUpload.getBucketName(),
            sliceUpload.getObjectName(), sliceUpload.getUploadId());
    return BuilderTool.of(TaskInfo.class)
            .with(TaskInfo::setFilename, sliceUpload.getFilename())
            .with(TaskInfo::setFileIdentifier, sliceUpload.getFileIdentifier())
            .with(TaskInfo::setBucketName, sliceUpload.getBucketName())
            .with(TaskInfo::setObjectName, sliceUpload.getObjectName())
            .with(TaskInfo::setUploadId, sliceUpload.getUploadId())
            .with(TaskInfo::setTotalSize, sliceUpload.getTotalSize())
            .with(TaskInfo::setChunkSize, sliceUpload.getChunkSize())
            .with(TaskInfo::setChunkNum, sliceUpload.getChunkNum())
            .with(TaskInfo::setExistsParts, parts)
            .with(TaskInfo::setFinish, YesNoEnum.NO.getValue())
            .build();
}

@Override
public TaskInfo initTask(InitTaskParam param) throws Exception {
    String filename = param.getFilename();
    String bucketName = ossProperties.getDefaultBucket();
    String suffix = filename.substring(filename.lastIndexOf(".") + 1);
    String objectName = StrUtil.format("{}.{}", IdUtil.randomUUID(), suffix);

    // 从S3获取上传id
    InitiateMultipartUploadResult initiateMultipartUploadResult = ossTemplate.initMultiUpload(bucketName, objectName);
    String uploadId = initiateMultipartUploadResult.getUploadId();

    // 持久化到数据库
    int chunkNum = (int) Math.ceil(param.getTotalSize() * 1.0 / param.getChunkSize());
    SliceUpload sliceUpload = BuilderTool.of(SliceUpload.class)
            .with(SliceUpload::setFilename, param.getFilename())
            .with(SliceUpload::setFileIdentifier, param.getFileIdentifier())
            .with(SliceUpload::setBucketName, bucketName)
            .with(SliceUpload::setObjectName, objectName)
            .with(SliceUpload::setUploadId, uploadId)
            .with(SliceUpload::setTotalSize, param.getTotalSize())
            .with(SliceUpload::setChunkSize, param.getChunkSize())
            .with(SliceUpload::setChunkNum, chunkNum)
            .build();
    sliceUploadService.save(sliceUpload);

    // 返回结果
    return BuilderTool.of(TaskInfo.class)
            .with(TaskInfo::setUploadId, sliceUpload.getUploadId())
            .with(TaskInfo::setBucketName, sliceUpload.getBucketName())
            .with(TaskInfo::setObjectName, sliceUpload.getObjectName())
            .with(TaskInfo::setFinish, YesNoEnum.NO.getValue())
            .build();
}

@Override
public String getPreSignUploadUrl(String bucketName, String objectName, Date expireAt, Map&lt;String, String&gt; params) throws Exception {
    return ossTemplate.getPreSignUploadUrl(bucketName, objectName, expireAt, params);
}

@Override
public UploadPartResult uploadPart(String bucketName, String objectName, String uploadId, InputStream inputStream, Integer partNumber) throws Exception {
    SliceUpload sliceUpload = sliceUploadService.querySliceUpload(bucketName, objectName, uploadId);
    if (Objects.isNull(sliceUpload)) {
        throw BizException.throwException("未找到上传信息! bucketName: %s, bucketName: %s, bucketName: %s",
                bucketName, objectName, uploadId);
    }
    return ossTemplate.uploadPart(bucketName, objectName, uploadId, inputStream, partNumber);
}

@Override
public List&lt;PartSummary&gt; listParts(String bucketName, String objectName, String uploadId) throws Exception {
    return ossTemplate.listParts(bucketName, objectName, uploadId);
}

@Override
public CompleteMultipartUploadResult completeMultiUpload(String bucketName, String objectName, String uploadId, Integer chunkNum) throws Exception {
    return ossTemplate.completeMultiUpload(bucketName, objectName, uploadId, chunkNum);
}
</code></pre>
<h3 id="54-接口调用示例">5.4 接口调用示例</h3>
<p><strong>注意：</strong> MinIO S3 等对文件分片大小有要求(&gt; 5MB)，太小的文件不支持合并</p>
<pre><code class="language-shell"># 上传前的校验
curl -X GET 'http://localhost:10030/demo/oss/chunkUpload/validate/file-md5'

# 初始化上传任务
curl -X POST 'http://localhost:10030/demo/oss/chunkUpload/initTask' \
--header 'MockSeed: 1' \
--header 'Content-Type: application/json' \
--data-raw '{
    "fileIdentifier": "file-md5",
    "filename": "temp.yaml",
    "totalSize": 265135,
    "chunkSize": 102400,
    "chunkNum": 3
}'

# 上传分片
curl -X POST 'http://localhost:10030/demo/oss/chunkUpload/uploadPart' \
--header 'MockSeed: 1' \
--form 'bucketName="light"' \
--form 'objectName="b16f23a1-fcd5-4bc1-a4b6-2d9034f58f87.yaml"' \
--form 'uploadId="YjIxYmUxZDgtMGFiYS00NGU3LWJlNTUtM2JiZTU2MWI2ZmJmLjc1YmVmODBiLWY4MDgtNDZiMi05ODQ3LWE1OTU1NjNlYWE0Mg"' \
--form 'partNumber="1"' \
--form 'file=@C:/Users/light/Desktop/temp.yaml.1'

curl -X POST 'http://localhost:10030/demo/oss/chunkUpload/uploadPart' \
--header 'MockSeed: 1' \
--form 'bucketName="light"' \
--form 'objectName="b16f23a1-fcd5-4bc1-a4b6-2d9034f58f87.yaml"' \
--form 'uploadId="YjIxYmUxZDgtMGFiYS00NGU3LWJlNTUtM2JiZTU2MWI2ZmJmLjc1YmVmODBiLWY4MDgtNDZiMi05ODQ3LWE1OTU1NjNlYWE0Mg"' \
--form 'partNumber="2"' \
--form 'file=@C:/Users/light/Desktop/temp.yaml.2'

curl -X POST 'http://localhost:10030/demo/oss/chunkUpload/uploadPart' \
--header 'MockSeed: 1' \
--form 'bucketName="light"' \
--form 'objectName="b16f23a1-fcd5-4bc1-a4b6-2d9034f58f87.yaml"' \
--form 'uploadId="YjIxYmUxZDgtMGFiYS00NGU3LWJlNTUtM2JiZTU2MWI2ZmJmLjc1YmVmODBiLWY4MDgtNDZiMi05ODQ3LWE1OTU1NjNlYWE0Mg"' \
--form 'partNumber="3"' \
--form 'file=@C:/Users/light/Desktop/temp.yaml.3'

# 分片列表
curl -X GET 'http://localhost:10030/demo/oss/chunkUpload/listParts?bucketName=light&amp;objectName=b16f23a1-fcd5-4bc1-a4b6-2d9034f58f87.yaml&amp;uploadId=YjIxYmUxZDgtMGFiYS00NGU3LWJlNTUtM2JiZTU2MWI2ZmJmLjc1YmVmODBiLWY4MDgtNDZiMi05ODQ3LWE1OTU1NjNlYWE0Mg'

# 获取预签名上传地址
curl -X GET 'http://localhost:10030/demo/oss/chunkUpload/file-md5/1' --header 'MockSeed: 1'

# 合并分片
curl -X GET 'http://localhost:10030/demo/oss/chunkUpload/merge/file-md5'
</code></pre>]]></content:encoded>
            <author>whitetulips@163.com (Hui Liu)</author>
            <category>upload</category>
            <category>minio</category>
            <category>s3</category>
            <category>oss</category>
            <category>localFileSystem</category>
        </item>
        <item>
            <title><![CDATA[Docusaurus With Algolia]]></title>
            <link>https://lorchr.github.io/light-docusaurus/blog/2023/08/07/docusaurus-with-aglolia</link>
            <guid>https://lorchr.github.io/light-docusaurus/blog/2023/08/07/docusaurus-with-aglolia</guid>
            <pubDate>Mon, 07 Aug 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[- Alogolia Offical]]></description>
            <content:encoded><![CDATA[<ul>
<li><a href="https://www.algolia.com/">Alogolia Offical</a></li>
<li><a href="https://github.com/algolia">Alogolia Github</a></li>
<li><a href="https://docsearch.algolia.com/">Algolia Docsearch 开发者试用</a></li>
<li><a href="https://crawler.algolia.com/admin/users/login">Algolia Crawler 爬虫</a></li>
<li><a href="https://docusaurus.io/zh-CN/docs/search#using-algolia-docsearch">Algolia DocSearch 插件文档</a></li>
<li><a href="https://docusaurus.io/zh-CN/docs/api/plugins/@docusaurus/plugin-sitemap">sitemap 插件文档</a></li>
<li><a href="https://docusaurus.io/docs/search#using-algolia-docsearch">Docusaurus integrate Algolia</a></li>
</ul>
<h2 id="1-注册algolia账号申请-docsearch">1. 注册Algolia账号，申请 Docsearch</h2>
<p><a href="https://docusaurus.io/zh-CN/docs/search#using-algolia-docsearch">Docusaurus集成Algolia</a></p>
<ol>
<li>使用Github账号注册<a href="https://dashboard.algolia.com/users/sign_in">Algolia</a></li>
<li>去<a href="https://docsearch.algolia.com/">Docsearch</a>申请，需要填写以下内容<!-- -->
<ol>
<li>Github pages 地址: <a href="https://lorchr.github.io/light-docusaurus/">https://lorchr.github.io/light-docusaurus/</a></li>
<li>邮箱 <a href="mailto:whitetulips@163.com">whitetulips@163.com</a></li>
<li>仓库地址 <a href="https://github.com/lorchr/light-docusaurus">https://github.com/lorchr/light-docusaurus</a></li>
</ol>
</li>
<li>等待审核，审核通过会收到一封邮件</li>
</ol>
<h2 id="2-创建-application">2. 创建 Application</h2>
<ol>
<li>登录<a href="https://dashboard.algolia.com/users/sign_in">Algolia官网</a></li>
<li>创建Application，设置名称，选择免费计划</li>
<li>控制台打开，设置页面，点击 API Keys，记录以下内容<!-- -->
<ol>
<li>Application ID</li>
<li>Search-Only API Key</li>
<li>Admin API Key</li>
</ol>
</li>
</ol>
<h2 id="3-web端部署爬虫">3. Web端部署爬虫</h2>
<ol>
<li>在DocSearch审核通过后，建立应用及索引，获取<code>APPLICAITON_ID</code>及<code>API_KEY</code></li>
<li>使用Algolia账号登录<a href="https://crawler.algolia.com/admin/users/login">Algolia Crawler</a></li>
<li>使用官方模板配置<a href="https://docsearch.algolia.com/docs/templates#docusaurus-v3-template">Docusaurus v3 template</a>部署爬虫</li>
</ol>
<pre><code class="language-js">new Crawler({
  appId: 'TLGHDZ3Y2I',
  apiKey: '0b9a9b1f4fd5fbe9a1962088169c1262',
  rateLimit: 8,
  maxDepth: 10,
  startUrls: ['https://lorchr.github.io/light-docusaurus/'],
  sitemaps: ['https://lorchr.github.io/light-docusaurus/sitemap.xml'],
  ignoreCanonicalTo: true,
  discoveryPatterns: ['https://lorchr.github.io/light-docusaurus/**'],
  actions: [
    {
      indexName: 'light-docusaurus',
      pathsToMatch: ['https://lorchr.github.io/light-docusaurus/**'],
      recordExtractor: ({ $, helpers }) =&gt; {
        // priority order: deepest active sub list header -&gt; navbar active item -&gt; 'Documentation'
        const lvl0 =
          $(
            '.menu__link.menu__link--sublist.menu__link--active, .navbar__item.navbar__link--active'
          )
            .last()
            .text() || 'Documentation';

        return helpers.docsearch({
          recordProps: {
            lvl0: {
              selectors: '',
              defaultValue: lvl0,
            },
            lvl1: ['header h1', 'article h1'],
            lvl2: 'article h2',
            lvl3: 'article h3',
            lvl4: 'article h4',
            lvl5: 'article h5, article td:first-child',
            lvl6: 'article h6',
            content: 'article p, article li, article td:last-child',
          },
          indexHeadings: true,
          aggregateContent: true,
          recordVersion: 'v3',
        });
      },
    },
  ],
  initialIndexSettings: {
    YOUR_INDEX_NAME: {
      attributesForFaceting: [
        'type',
        'lang',
        'language',
        'version',
        'docusaurus_tag',
      ],
      attributesToRetrieve: [
        'hierarchy',
        'content',
        'anchor',
        'url',
        'url_without_anchor',
        'type',
      ],
      attributesToHighlight: ['hierarchy', 'content'],
      attributesToSnippet: ['content:10'],
      camelCaseAttributes: ['hierarchy', 'content'],
      searchableAttributes: [
        'unordered(hierarchy.lvl0)',
        'unordered(hierarchy.lvl1)',
        'unordered(hierarchy.lvl2)',
        'unordered(hierarchy.lvl3)',
        'unordered(hierarchy.lvl4)',
        'unordered(hierarchy.lvl5)',
        'unordered(hierarchy.lvl6)',
        'content',
      ],
      distinct: true,
      attributeForDistinct: 'url',
      customRanking: [
        'desc(weight.pageRank)',
        'desc(weight.level)',
        'asc(weight.position)',
      ],
      ranking: [
        'words',
        'filters',
        'typo',
        'attribute',
        'proximity',
        'exact',
        'custom',
      ],
      highlightPreTag: '&lt;span class="algolia-docsearch-suggestion--highlight"&gt;',
      highlightPostTag: '&lt;/span&gt;',
      minWordSizefor1Typo: 3,
      minWordSizefor2Typos: 7,
      allowTyposOnNumericTokens: false,
      minProximity: 1,
      ignorePlurals: true,
      advancedSyntax: true,
      attributeCriteriaComputedByMinProximity: true,
      removeWordsIfNoResults: 'allOptional',
      separatorsToIndex: '_',
    },
  },
});
</code></pre>
<h2 id="4-配置-docusaurus">4. 配置 Docusaurus</h2>
<ol>
<li>配置 .env (键值不带双引号)</li>
</ol>
<pre><code class="language-bash">APPLICATION_ID=Application ID
API_KEY=Admin API Key # 务必确认, 这是坑点 不要用 'Write API Key' 或者 'Search API Key'
</code></pre>
<ol start="2">
<li>docusaurus.config.js</li>
</ol>
<pre><code class="language-js">module.exports = {
  // ...
  presets: [[
    // ...
    "classic",
    /** @type {import('@docusaurus/preset-classic').Options} */
    ({
      // 这个插件会为你的站点创建一个站点地图
      // 以便搜索引擎的爬虫能够更准确地爬取你的网站
      sitemap: {
        changefreq: "weekly",
        priority: 0.5,
        ignorePatterns: ["/tags/**"],
        filename: "sitemap.xml",
      },
    })
  ]],
  // ...
  themeConfig: {
    // ...
    algolia: {
      appId: 'YOUR_APP_ID', // Application ID
      //  公开 API密钥：提交它没有危险
      apiKey: 'YOUR_SEARCH_API_KEY', //  Search-Only API Key
      indexName: 'YOUR_INDEX_NAME'
    },
  }
}
</code></pre>
<ol start="3">
<li>docsearch-config.json (爬虫配置文件)</li>
</ol>
<p>需修改3处:</p>
<ul>
<li>index_name</li>
<li>start_urls</li>
<li>sitemap_urls</li>
</ul>
<pre><code class="language-js">{
  "index_name": "light-docusaurus",
  "start_urls": [
    "https://lorchr.github.io/light-docusaurus/"
  ],
  "sitemap_urls": [
    "https://lorchr.github.io/light-docusaurus/sitemap.xml"
  ],
  "sitemap_alternate_links": true,
  "stop_urls": [
    "/tests"
  ],
  "selectors": {
    "lvl0": {
      "selector": "(//ul[contains(@class,'menu__list')]//a[contains(@class, 'menu__link menu__link--sublist menu__link--active')]/text() | //nav[contains(@class, 'navbar')]//a[contains(@class, 'navbar__link--active')]/text())[last()]",
      "type": "xpath",
      "global": true,
      "default_value": "Documentation"
    },
    "lvl1": "header h1",
    "lvl2": "article h2",
    "lvl3": "article h3",
    "lvl4": "article h4",
    "lvl5": "article h5, article td:first-child",
    "lvl6": "article h6",
    "text": "article p, article li, article td:last-child"
  },
  "strip_chars": " .,;:#",
  "custom_settings": {
    "separatorsToIndex": "_",
    "attributesForFaceting": [
      "language",
      "version",
      "type",
      "docusaurus_tag"
    ],
    "attributesToRetrieve": [
      "hierarchy",
      "content",
      "anchor",
      "url",
      "url_without_anchor",
      "type"
    ]
  },
  "js_render": true,
  "conversation_id": [
    "833762294"
  ],
  "nb_hits": 46250
}
</code></pre>
<h2 id="5-执行爬虫程序---docsearch-scraper">5. 执行爬虫程序 - docsearch-scraper</h2>
<h3 id="1-本地-执行爬虫">1. 本地 执行爬虫</h3>
<p>前置条件:</p>
<ul>
<li>Docker</li>
<li>jq - 轻量级命令行 JSON 处理器<a href="https://github.com/stedolan/jq/wiki/Installation#zero-install">使用 brew 安装最新版的 jq</a></li>
</ul>
<p>jq安装完成后, 在命令行执行 爬虫脚本</p>
<pre><code class="language-shell">docker run -it --env-file=.env -e "CONFIG=$(cat docsearch-config.json | jq -r tostring)" algolia/docsearch-scraper
</code></pre>
<p>等待 容器运行完成, 如下即可</p>
<pre><code class="language-shell">Getting https://lorchr.github.io/light-docusaurus/docs/react/hooks/custom-hooks from selenium
Getting https://lorchr.github.io/light-docusaurus/docs/react/hooks/useMemo from selenium
Getting https://lorchr.github.io/light-docusaurus/docs/react/hooks/useCallback from selenium
Getting https://lorchr.github.io/light-docusaurus/docs/javascript/versions/es-2016 from selenium
Getting https://lorchr.github.io/light-docusaurus/docs/javascript/versions/es-2015 from selenium
&gt; DocSearch: https://lorchr.github.io/light-docusaurus/docs/plugins-and-libraries/big-screen/ 17 records)
&gt; DocSearch: https://lorchr.github.io/light-docusaurus/docs/server/nginx/nginx-forward-proxy-vs-reverse-proxy/ 8 records)
&gt; DocSearch: https://lorchr.github.io/light-docusaurus/docs/category/caddy/ 3 records)
&gt; DocSearch: https://lorchr.github.io/light-docusaurus/docs/category/nginx/ 5 records)

Nb hits: 1369
</code></pre>
<h3 id="2-github-actions-执行爬虫">2. GitHub Actions 执行爬虫</h3>
<p>在 <code>.github/workflows/</code> 文件夹下 创建 <code>docsearch-scraper.yml</code>, 用来定义 GitHub Actions 工作流</p>
<p>docsearch-scraper.yml</p>
<pre><code class="language-yaml">name: DocSearch-Scraper

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  scan:
    runs-on: ubuntu-latest

    steps:
      - name: Sleep for 10 seconds
        run: sleep 10s
        shell: bash

      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Run scraper
        env:
          APPLICATION_ID: ${{ secrets.ALGOLIA_APPLICATION_ID }}
          API_KEY: ${{ secrets.ALGOLIA_API_KEY }}
        run: |
          CONFIG="$(cat docsearch-config.json)"
          docker run -i --rm \
                  -e APPLICATION_ID=$APPLICATION_ID \
                  -e API_KEY=$API_KEY \
                  -e CONFIG="${CONFIG}" \
                  algolia/docsearch-scraper
</code></pre>
<p>然后在 GitHub 的 Secrets 创建</p>
<ul>
<li>APPLICATION_ID</li>
<li>API_KEY</li>
</ul>
<p>当使用 Git 推送项目到 GitHub时, Actions就会自动执行 爬虫任务</p>
<p><a href="https://didilinkin.cn/blog/algoliasearch">在 Docusaurus v2 中使用 Algolia DocSearch搜索功能</a></p>]]></content:encoded>
            <author>whitetulips@163.com (Hui Liu)</author>
            <category>docusaurus</category>
            <category>algolia</category>
            <category>docsearch</category>
            <category>crawler</category>
        </item>
        <item>
            <title><![CDATA[Welcome]]></title>
            <link>https://lorchr.github.io/light-docusaurus/blog/welcome</link>
            <guid>https://lorchr.github.io/light-docusaurus/blog/welcome</guid>
            <pubDate>Thu, 26 Aug 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Docusaurus blogging features are powered by the blog plugin.]]></description>
            <content:encoded><![CDATA[<p><a href="https://docusaurus.io/docs/blog">Docusaurus blogging features</a> are powered by the <a href="https://docusaurus.io/docs/api/plugins/@docusaurus/plugin-content-blog">blog plugin</a>.</p>
<p>Simply add Markdown files (or folders) to the <code>blog</code> directory.</p>
<p>Regular blog authors can be added to <code>authors.yml</code>.</p>
<p>The blog post date can be extracted from filenames, such as:</p>
<ul>
<li><code>2019-05-30-welcome.md</code></li>
<li><code>2019-05-30-welcome/index.md</code></li>
</ul>
<p>A blog post folder can be convenient to co-locate blog post images:</p>
<p><img alt="Docusaurus Plushie" src="https://lorchr.github.io/light-docusaurus/assets/images/docusaurus-plushie-banner-a60f7593abca1e3eef26a9afa244e4fb.jpeg" width="1500" height="500"></p>
<p>The blog supports tags as well!</p>
<p><strong>And if you don't want a blog</strong>: just delete this directory, and use <code>blog: false</code> in your Docusaurus config.</p>]]></content:encoded>
            <category>facebook</category>
            <category>hello</category>
            <category>docusaurus</category>
        </item>
        <item>
            <title><![CDATA[MDX Blog Post]]></title>
            <link>https://lorchr.github.io/light-docusaurus/blog/mdx-blog-post</link>
            <guid>https://lorchr.github.io/light-docusaurus/blog/mdx-blog-post</guid>
            <pubDate>Sun, 01 Aug 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Blog posts support Docusaurus Markdown features, such as MDX.]]></description>
            <content:encoded><![CDATA[<p>Blog posts support <a href="https://docusaurus.io/docs/markdown-features">Docusaurus Markdown features</a>, such as <a href="https://mdxjs.com/">MDX</a>.</p>
<admonition type="tip"><p>Use the power of React to create interactive blog posts.</p><pre><code class="language-js">&lt;button onClick={() =&gt; alert('button clicked!')}&gt;Click me!&lt;/button&gt;
</code></pre><button>Click me!</button></admonition>]]></content:encoded>
            <category>docusaurus</category>
        </item>
        <item>
            <title><![CDATA[Long Blog Post]]></title>
            <link>https://lorchr.github.io/light-docusaurus/blog/long-blog-post</link>
            <guid>https://lorchr.github.io/light-docusaurus/blog/long-blog-post</guid>
            <pubDate>Wed, 29 May 2019 00:00:00 GMT</pubDate>
            <description><![CDATA[This is the summary of a very long blog post,]]></description>
            <content:encoded><![CDATA[<p>This is the summary of a very long blog post,</p>
<p>Use a <code>&lt;!--</code> <code>truncate</code> <code>--&gt;</code> comment to limit blog post size in the list view.</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>]]></content:encoded>
            <category>hello</category>
            <category>docusaurus</category>
        </item>
        <item>
            <title><![CDATA[First Blog Post]]></title>
            <link>https://lorchr.github.io/light-docusaurus/blog/first-blog-post</link>
            <guid>https://lorchr.github.io/light-docusaurus/blog/first-blog-post</guid>
            <pubDate>Tue, 28 May 2019 00:00:00 GMT</pubDate>
            <description><![CDATA[Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet]]></description>
            <content:encoded><![CDATA[<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>]]></content:encoded>
            <category>hola</category>
            <category>docusaurus</category>
        </item>
    </channel>
</rss>